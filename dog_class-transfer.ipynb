{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7cceb087-87ab-4bab-9982-da3e77660258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import PIL.Image as Image\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "import datetime\n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a45a0851-6d0d-493c-b89a-00e1f79624d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenet_v2 =\"https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4\"\n",
    "IMAGE_SHAPE = (224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e37c6a9-11c9-454c-b14c-d3e079e4017a",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_path = tf.keras.utils.get_file('ImageNetLabels.txt','https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt')\n",
    "imagenet_labels = np.array(open(labels_path).read().splitlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54bb9411-b20b-4f14-8532-ed0ce77b8c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 70432 files belonging to 130 classes.\n",
      "Using 56346 files for training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-01 19:11:09.536693: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-01 19:11:09.586801: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-01 19:11:09.587046: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-01 19:11:09.587891: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-01 19:11:09.588100: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-01 19:11:09.588289: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-01 19:11:09.673672: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-01 19:11:09.673920: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-01 19:11:09.674099: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-01 19:11:09.674234: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 243 MB memory:  -> device: 0, name: NVIDIA GeForce MX150, pci bus id: 0000:01:00.0, compute capability: 6.1\n",
      "2024-03-01 19:11:10.007987: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 70432 files belonging to 130 classes.\n",
      "Using 14086 files for validation.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "data_dir = '../low-resolution'\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size,\n",
    "  shuffle = True  \n",
    ")\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size,\n",
    "  shuffle = True  \n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cee42f5d-13d7-4891-842c-b49a2624d332",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = np.array(train_ds.class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ca37bd3-6e0b-4a50-a8f0-91282b2156e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf0f2255-21e8-454c-a190-52429ebcb6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor_model = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\"\n",
    "\n",
    "pretrained_model_without_top_layer = hub.KerasLayer(\n",
    "    feature_extractor_model, input_shape=(224, 224, 3), trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d83bbe81-9120-45d1-998c-d7b1d29d6e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
    "train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y)) # Where x—images, y—labels.\n",
    "val_ds = val_ds.map(lambda x, y: (normalization_layer(x), y)) # Where x—images, y—labels.\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03ad309e-d9f4-4437-911a-17ad4ac61165",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7e28787-d369-4bde-bd47-0181a5b6944c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " random_flip (RandomFlip)    (None, 224, 224, 3)       0         \n",
      "                                                                 \n",
      " random_rotation (RandomRot  (None, 224, 224, 3)       0         \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " random_zoom (RandomZoom)    (None, 224, 224, 3)       0         \n",
      "                                                                 \n",
      " keras_layer_1 (KerasLayer)  (None, 1280)              2257984   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 130)               166530    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2424514 (9.25 MB)\n",
      "Trainable params: 166530 (650.51 KB)\n",
      "Non-trainable params: 2257984 (8.61 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dog_classes_count = len(class_names)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "      keras.layers.RandomFlip(\"horizontal\",\n",
    "                      input_shape=(img_height,\n",
    "                                  img_width,\n",
    "                                  3)),\n",
    "  keras.layers.RandomRotation(0.1),\n",
    "  keras.layers.RandomZoom(0.1),\n",
    "  pretrained_model_without_top_layer,\n",
    "  tf.keras.layers.Dense(dog_classes_count)\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a78f1c73-82a3-4f4a-8c4a-5994f8bd6b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.compile(\n",
    "  optimizer=\"adam\",\n",
    "  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "  metrics=['acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "681908a4-f820-40dd-8401-72cd4a80f0af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-01 14:11:00.240171: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904\n",
      "2024-03-01 14:11:00.604360: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-03-01 14:11:06.082610: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f829aba7010 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-03-01 14:11:06.082646: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce MX150, Compute Capability 6.1\n",
      "2024-03-01 14:11:06.106390: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1709295066.260991    4066 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1761/1761 [==============================] - 477s 266ms/step - loss: 1.2282 - acc: 0.6561 - val_loss: 0.8356 - val_acc: 0.7435\n",
      "Epoch 2/20\n",
      "1761/1761 [==============================] - 456s 259ms/step - loss: 0.9404 - acc: 0.7187 - val_loss: 0.8434 - val_acc: 0.7417\n",
      "Epoch 3/20\n",
      "1761/1761 [==============================] - 456s 259ms/step - loss: 0.8642 - acc: 0.7372 - val_loss: 0.8085 - val_acc: 0.7532\n",
      "Epoch 4/20\n",
      "1761/1761 [==============================] - 455s 258ms/step - loss: 0.8195 - acc: 0.7454 - val_loss: 0.8225 - val_acc: 0.7516\n",
      "Epoch 5/20\n",
      "1761/1761 [==============================] - 455s 258ms/step - loss: 0.7875 - acc: 0.7536 - val_loss: 0.8507 - val_acc: 0.7436\n",
      "Epoch 6/20\n",
      "1761/1761 [==============================] - 456s 259ms/step - loss: 0.7589 - acc: 0.7627 - val_loss: 0.8229 - val_acc: 0.7462\n",
      "Epoch 7/20\n",
      "1761/1761 [==============================] - 456s 259ms/step - loss: 0.7431 - acc: 0.7649 - val_loss: 0.8545 - val_acc: 0.7513\n",
      "Epoch 8/20\n",
      "1761/1761 [==============================] - 456s 259ms/step - loss: 0.7293 - acc: 0.7685 - val_loss: 0.8476 - val_acc: 0.7505\n",
      "Epoch 9/20\n",
      "1761/1761 [==============================] - 457s 259ms/step - loss: 0.7004 - acc: 0.7764 - val_loss: 0.8749 - val_acc: 0.7394\n",
      "Epoch 10/20\n",
      "1761/1761 [==============================] - 459s 260ms/step - loss: 0.6922 - acc: 0.7777 - val_loss: 0.8633 - val_acc: 0.7478\n",
      "Epoch 11/20\n",
      "1761/1761 [==============================] - 457s 260ms/step - loss: 0.6792 - acc: 0.7802 - val_loss: 0.8831 - val_acc: 0.7485\n",
      "Epoch 12/20\n",
      "1761/1761 [==============================] - 456s 259ms/step - loss: 0.6747 - acc: 0.7825 - val_loss: 0.9037 - val_acc: 0.7424\n",
      "Epoch 13/20\n",
      "1761/1761 [==============================] - 458s 260ms/step - loss: 0.6579 - acc: 0.7868 - val_loss: 0.8906 - val_acc: 0.7443\n",
      "Epoch 14/20\n",
      "1761/1761 [==============================] - 456s 259ms/step - loss: 0.6510 - acc: 0.7883 - val_loss: 0.9054 - val_acc: 0.7385\n",
      "Epoch 15/20\n",
      "1761/1761 [==============================] - 456s 259ms/step - loss: 0.6497 - acc: 0.7882 - val_loss: 0.8977 - val_acc: 0.7460\n",
      "Epoch 16/20\n",
      "1761/1761 [==============================] - 459s 260ms/step - loss: 0.6414 - acc: 0.7920 - val_loss: 0.9137 - val_acc: 0.7472\n",
      "Epoch 17/20\n",
      "1761/1761 [==============================] - 459s 260ms/step - loss: 0.6385 - acc: 0.7916 - val_loss: 0.9177 - val_acc: 0.7431\n",
      "Epoch 18/20\n",
      "1761/1761 [==============================] - 456s 259ms/step - loss: 0.6322 - acc: 0.7958 - val_loss: 0.9684 - val_acc: 0.7367\n",
      "Epoch 19/20\n",
      "1761/1761 [==============================] - 459s 260ms/step - loss: 0.6158 - acc: 0.7987 - val_loss: 0.9406 - val_acc: 0.7324\n",
      "Epoch 20/20\n",
      "1761/1761 [==============================] - 460s 261ms/step - loss: 0.6234 - acc: 0.7980 - val_loss: 0.9439 - val_acc: 0.7381\n"
     ]
    }
   ],
   "source": [
    "epochs=20\n",
    "history = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=epochs,\n",
    "  batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ff9483b5-ae05-497e-9af5-9ff9d837dec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8580 files belonging to 120 classes.\n"
     ]
    }
   ],
   "source": [
    "test_ds= tf.keras.utils.image_dataset_from_directory(\n",
    "  'archive/cropped/test',\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "efdcdacf-47d0-461e-ae0c-22bfb8e555c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import Precision, Recall, BinaryAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4ea4ee7a-babb-4045-81b3-9ecc937c63f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = Precision()\n",
    "re = Recall()\n",
    "acc = BinaryAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5cb7f0f7-a95a-4a80-aa28-59a9f2cbedc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = test_ds.map(lambda x, y: (normalization_layer(x), y)) # Where x—images, y—labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c407a40c-839e-4604-b04a-1366019b1c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269/269 [==============================] - 55s 206ms/step - loss: 0.5655 - acc: 0.8244\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5654774308204651, 0.8243589997291565]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2f52dc-173a-4707-9d41-5ebbc728dbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('saved_model/2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a66f72c7-9261-4acb-8b7a-619890dce323",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1d92b00-c7ec-4d26-95fc-ea1d9157854f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_model = load_model('saved_model/2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "190b991d-f588-48bd-8ed4-cb12e483f312",
   "metadata": {},
   "outputs": [],
   "source": [
    "grace_hopper = np.array(grace_hopper)/255.0\n",
    "import sys\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "array = grace_hopper[np.newaxis, ...]\n",
    "import json\n",
    "y = json.dumps(array.tolist(),separators=(',', ':'), \n",
    "          sort_keys=True, \n",
    "          indent=4)\n",
    "\n",
    "f = open(\"demofile3.txt\", \"w\")\n",
    "f.write(y)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a105f7f3-2e92-4bc1-ac0e-05011701e4d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://i.ytimg.com/vi/-ylolmt2e6o/hq720.jpg?sqp=-oaymwEhCK4FEIIDSFryq4qpAxMIARUAAAAAGAElAADIQj0AgKJD&rs=AOn4CLA58XAExELq9exmSeiwGNYiy5ZjhA\n",
      "109975/109975 [==============================] - 0s 0us/step\n",
      "1/1 [==============================] - 0s 36ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('n02106662-German_shepherd', 99.56305027008057)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sunflower_url = \"https://i.ytimg.com/vi/-ylolmt2e6o/hq720.jpg?sqp=-oaymwEhCK4FEIIDSFryq4qpAxMIARUAAAAAGAElAADIQj0AgKJD&rs=AOn4CLA58XAExELq9exmSeiwGNYiy5ZjhA\"\n",
    "sunflower_path = tf.keras.utils.get_file('a', origin=sunflower_url)\n",
    "img = tf.keras.utils.load_img(sunflower_path, target_size=(224, 224))\n",
    "img = np.array(img)/255.0\n",
    "\n",
    "img_array = tf.expand_dims(img, 0) \n",
    "predicted_img(img_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4cdc9b7e-ea06-4821-a38e-fa778942160c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 25ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('200-n000008-Airedale', 87.72645592689514)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = Image.open('../image-test/airedale.jpeg').resize((224,224))\n",
    "img = np.array(img)/ 255\n",
    "\n",
    "img = tf.expand_dims(img, 0) \n",
    "predicted_img(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c94a60e-dd7e-4ef9-b62c-cb21dcb10712",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predicted_img(img_array):\n",
    "    predicted = trans_model.predict(img_array)\n",
    "    score = tf.nn.softmax(predicted[0])\n",
    "    predicted = np.argmax(predicted, axis=1)\n",
    "    return class_names[predicted][0] , 100 * np.max(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ebadc106-b984-451e-b0ee-2636999cb329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 26ms/step\n",
      "n02085620-Chihuahua--predicted:\n",
      "n02085620-Chihuahua\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "n02092002-Scottish_deerhound--predicted:\n",
      "n02092002-Scottish_deerhound\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "n02107683-Bernese_mountain_dog--predicted:\n",
      "n02107683-Bernese_mountain_dog\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "n02092339-Weimaraner--predicted:\n",
      "n02092339-Weimaraner\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "n02098413-Lhasa--predicted:\n",
      "n02098413-Lhasa\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "n02101388-Brittany_spaniel--predicted:\n",
      "n02101388-Brittany_spaniel\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "n02090622-borzoi--predicted:\n",
      "n02090622-borzoi\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "n02096294-Australian_terrier--predicted:\n",
      "n02096294-Australian_terrier\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "for images, labels in train_ds.take(1):\n",
    "  for i in range(8):\n",
    "    predicted = model.predict((np.array(images[i]))[np.newaxis, ...])\n",
    "\n",
    "    predicted = np.argmax(predicted, axis=1)\n",
    "    actaul = class_names[labels[i]]\n",
    "    pred =  class_names[predicted][0] \n",
    "    print(actaul +'--predicted:\\n' + pred)\n",
    "   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
